{
 "metadata": {
  "name": "",
  "signature": "sha256:50e02b51da900de519312d15c45b3a55bf74ff56361c6adb31f24c6c8a653c16"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this example, we are going "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys,os,re,time\n",
      "import urllib\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from IPython import parallel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Downloading some images"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This flickr parsing code is adapted from [here](http://megasnippets.com/source-codes/python/get_random_interesting_image_flickr)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_urls(html):\n",
      "    \"\"\"Extract images URLs from a page.\"\"\"\n",
      "    re_imageurl = re.compile(r'src=\"(http://farm\\d+.static.?flickr.com/\\d+/\\d+_\\w+_t.jpg)\"',re.IGNORECASE|re.DOTALL)\n",
      "    urls = re_imageurl.findall(html)\n",
      "    if len(urls)==0:\n",
      "        return []\n",
      "    urls = [url.replace('_t.jpg','_m.jpg') for url in urls]\n",
      "    return urls\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def urls_for_tag(tag='face', min_images=100, max_pages=20):\n",
      "    \"\"\"get urls to flickr images with given tag(s)\n",
      "\n",
      "    scrapes flickr search page\n",
      "    \"\"\"\n",
      "    urls = []\n",
      "    page = 1\n",
      "    while len(urls) < min_images and page <= max_pages:\n",
      "        url = 'http://www.flickr.com/search/?q=%s&l=cc&ss=0&ct=0&mt=photos&w=all&adv=1&m=tags&page=%i' % (tag, page)\n",
      "        print \"fetching %s\" % url\n",
      "        urlfile = urllib.urlopen(url)\n",
      "        html= urlfile.read()\n",
      "        urlfile.close()\n",
      "        page_urls = extract_urls(html)\n",
      "        urls.extend(page_urls)\n",
      "        print \"found %i images\" % len(urls)\n",
      "        page += 1\n",
      "        \n",
      "    return urls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "urls = urls_for_tag('portrait', 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def download_image(url, dest_dir='images'):\n",
      "    \"\"\"download an image from a url into a directory\n",
      "\n",
      "    returns the path to the downloaded image.\n",
      "    \"\"\"\n",
      "    basename = url.rsplit('/', 1)[-1]\n",
      "    dest = os.path.join(dest_dir, basename)\n",
      "    if not os.path.exists(dest_dir):\n",
      "        os.makedirs(dest_dir)\n",
      "    if os.path.exists(dest):\n",
      "        print \"already have %s\" % dest\n",
      "        return dest\n",
      "    \n",
      "    print \"downloading %s -> %s\" % (url, dest)\n",
      "    urlf = urllib.urlopen(url)\n",
      "    data = urlf.read()\n",
      "    urlf.close()\n",
      "    with open(dest, 'w') as f:\n",
      "        f.write(data)\n",
      "    return dest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.io import imread\n",
      "from skimage import measure"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_contours(path):\n",
      "    img = imread(path, flatten=True)\n",
      "    \n",
      "    # Find contours at a constant value of 0.8\n",
      "    dark = measure.find_contours(img, 0.1)\n",
      "    light = measure.find_contours(img, 0.8)\n",
      "    return img, dark, light"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_contours(img, dark, light):\n",
      "    \"\"\"Display the image and plot all contours found\"\"\"\n",
      "    plt.imshow(img, cmap='gray')\n",
      "    \n",
      "    for n, contour in enumerate(dark):\n",
      "        plt.plot(contour[:, 1], contour[:, 0], c='r', linewidth=1)\n",
      "    \n",
      "    for n, contour in enumerate(light):\n",
      "        plt.plot(contour[:, 1], contour[:, 0], c='b', linewidth=1)\n",
      "\n",
      "    plt.axis('image')\n",
      "    plt.xticks([])\n",
      "    plt.yticks([])\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And finally, a two-step function that downloads an image from a url,\n",
      "and detects faces in it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def contours_in_url(url):\n",
      "    \"\"\"detect contours in an image downloaded from a url\"\"\"\n",
      "    img_path = download_image(url)\n",
      "    return find_contours(img_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the network doesn't work,\n",
      "you can just generate a list of paths to images on your computer.\n",
      "For instance, these pictures are just everything from my iPhoto thumbnails directory,\n",
      "so vary from ~320x240 - 1024x768"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "library = os.path.expanduser(\"~/Pictures/2012\")\n",
      "pictures = []\n",
      "for directory, subdirs, files in os.walk(os.path.join(library, 'Thumbnails')):\n",
      "    for fname in files:\n",
      "        if fname.endswith('.jpg'):\n",
      "            pictures.append(os.path.join(directory, fname))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or this one, which globs pictures from a particular folder:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "pictures = glob.glob(\"images/portrait/*.jpg\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's test our function locally, to see what it does"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for url in urls[:10]:\n",
      "    img, dark, light = contours_in_url(url)\n",
      "    plot_contours(img, dark, light)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the network isn't kind to you, we can skip the downloads,\n",
      "and just use pictures we have on the filesystem:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for p in pictures[:10]:\n",
      "    dark, light = find_contours(p)\n",
      "    plot_contours(p, dark, light)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Now in parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we connect our parallel Client"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = parallel.Client()\n",
      "all_engines = rc[:]\n",
      "view = rc.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then we initialize the namespace on all of the engines with imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from skimage.io import imread\n",
      "from skimage import measure"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and make sure some functions are defined everywhere (this is only necessary for the `contours_in_url` case)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_engines.push(dict(\n",
      "    find_contours=find_contours,\n",
      "    download_image=download_image,\n",
      "))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can iterate through all of our pictures, and detect and display any faces we find"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pictures = glob.glob(\"images/*/*.jpg\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tic = time.time()\n",
      "# if you are running offline, do this one:\n",
      "f = find_contours\n",
      "source = pictures\n",
      "\n",
      "# or you can download each image as part of the task:\n",
      "#f = contours_in_url\n",
      "#source = urls\n",
      "\n",
      "\n",
      "amr = view.map_async(f, source[:100], ordered=False)\n",
      "nfound = 0\n",
      "for img, dark, light in amr:\n",
      "    plot_contours(img, dark, light)\n",
      "\n",
      "toc = time.time()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}